{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T06:55:20.484404Z",
     "iopub.status.busy": "2025-05-14T06:55:20.483407Z",
     "iopub.status.idle": "2025-05-14T06:55:22.542317Z",
     "shell.execute_reply": "2025-05-14T06:55:22.542317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3845 entries, 2011-12-22 to 2025-05-13\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   华东煤油-山东柴油价差        1150 non-null   float64\n",
      " 1   中国煤油产量/柴油产量        227 non-null    float64\n",
      " 2   原油：主营炼厂：加工量：中国（周）  227 non-null    float64\n",
      " 3   中国主营炼厂产能利用率        529 non-null    float64\n",
      " 4   山东汽油裂解差            2090 non-null   float64\n",
      " 5   芳烃化工品与烯烃化工品价差      3300 non-null   float64\n",
      " 6   MX（FOB韩国）-石脑油      882 non-null    float64\n",
      " 7   国内+国际航班执行数/7DMA    1502 non-null   float64\n",
      " 8   煤油：产量：中国（周）        227 non-null    float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 300.4 KB\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully as '煤柴价差日度.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "import time\n",
    "import base64\n",
    "from hashlib import sha256\n",
    "from hmac import HMAC\n",
    "\n",
    "import http.client\n",
    "import requests\n",
    "import pandas as pd \n",
    "\n",
    "APPID = \"tubmafwrzhpgfiuf\"\n",
    "SECRET = \"eotpcqbvhycdshwscqnytiwzbgonposs\"\n",
    "\n",
    "\n",
    "def generate_nonce(length=32):\n",
    "    \"\"\"Generate a random nonce.\"\"\"\n",
    "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
    "\n",
    "\n",
    "def get_timestamp():\n",
    "    \"\"\"Get the current timestamp.\"\"\"\n",
    "    return int(time.time())\n",
    "\n",
    "\n",
    "def build_sign_str(appid, nonce, timestamp):\n",
    "    \"\"\"Build the string to be signed.\"\"\"\n",
    "    return f'appid={appid}&nonce={nonce}&timestamp={timestamp}'\n",
    "\n",
    "\n",
    "def calculate_signature(secret, message):\n",
    "    \"\"\"Calculate the HMAC SHA-256 signature.\"\"\"\n",
    "    return base64.urlsafe_b64encode(HMAC(secret.encode('utf-8'), message.encode('utf-8'), sha256).digest()).decode('utf-8')\n",
    "\n",
    "\n",
    "def fetch_indicator_details(indicator_id):\n",
    "    \"\"\"Fetch the details for a specific indicator ID.\"\"\"\n",
    "    nonce = generate_nonce()\n",
    "    timestamp = get_timestamp()\n",
    "    sign_str = build_sign_str(APPID, nonce, timestamp)\n",
    "    signature = calculate_signature(SECRET, sign_str)\n",
    "\n",
    "    headers = {\n",
    "        'nonce': nonce,\n",
    "        'timestamp': str(timestamp),\n",
    "        'appid': APPID,\n",
    "        'signature': signature,\n",
    "        'Accept': \"*/*\",\n",
    "        'Accept-Encoding': \"gzip, deflate, br\",\n",
    "        'User-Agent': \"PostmanRuntime-ApipostRuntime/1.1.0\",\n",
    "        'Connection': \"keep-alive\",\n",
    "    }\n",
    "\n",
    "    url = f\"https://etahub.hzinsights.com/v1/edb/data?EdbCode={indicator_id}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get('Data')\n",
    "    else:\n",
    "        print(\n",
    "            f\"Failed to fetch data for ID {indicator_id}, status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def fetch_indicator_name(indicator_id):\n",
    "    \"\"\"Fetch the name for a specific indicator ID.\"\"\"\n",
    "    nonce = generate_nonce()\n",
    "    timestamp = get_timestamp()\n",
    "    sign_str = build_sign_str(APPID, nonce, timestamp)\n",
    "    signature = calculate_signature(SECRET, sign_str)\n",
    "\n",
    "    headers = {\n",
    "        'nonce': nonce,\n",
    "        'timestamp': str(timestamp),\n",
    "        'appid': APPID,\n",
    "        'signature': signature,\n",
    "        'Accept': \"*/*\",\n",
    "        'Accept-Encoding': \"gzip, deflate, br\",\n",
    "        'User-Agent': \"PostmanRuntime-ApipostRuntime/1.1.0\",\n",
    "        'Connection': \"keep-alive\",\n",
    "    }\n",
    "\n",
    "    url = f\"https://etahub.hzinsights.com/v1/edb/detail?EdbCode={indicator_id}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get('Data').get('EdbName')\n",
    "    else:\n",
    "        print(\n",
    "            f\"Failed to fetch data for ID {indicator_id}, status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # List of indicator IDs you want to fetch\n",
    "    indicator_ids = [\"C2503031431317922\", 'C2503031419559643','ID01232808','ID01232815','C2302239482','C2211303599','C2202096543','C2409200800407580','C2503031419559643','RE00033392']  # Add more IDs as needed\n",
    "\n",
    "    # Dictionary to store DataFrames for each indicator\n",
    "    data_frames = {}\n",
    "\n",
    "    for indicator_id in indicator_ids:\n",
    "        data = fetch_indicator_details(indicator_id)\n",
    "        if data:\n",
    "            # Create a DataFrame with DataTime as index\n",
    "            df = pd.DataFrame(data)\n",
    "            df['DataTime'] = pd.to_datetime(df['DataTime'])\n",
    "            df.set_index('DataTime', inplace=True)\n",
    "            df.sort_index(inplace=True)\n",
    "            # Only keep the 'Value' column and rename it to the indicator ID\n",
    "            df = df[['Value']].rename(columns={'Value': fetch_indicator_name(indicator_id)})\n",
    "            data_frames[indicator_id] = df\n",
    "\n",
    "    # Concatenate all DataFrames along the columns\n",
    "    if data_frames:\n",
    "        result_df = pd.concat(data_frames.values(), axis=1)\n",
    "        print(result_df.info())\n",
    "        result_df.to_excel(\"data_input_auto/煤柴价差日度.xlsx\")\n",
    "        print(\"Data saved successfully as '煤柴价差日度.xlsx'\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
