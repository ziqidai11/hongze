{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T08:11:06.569313Z",
     "iopub.status.busy": "2025-10-29T08:11:06.568618Z",
     "iopub.status.idle": "2025-10-29T08:11:09.462149Z",
     "shell.execute_reply": "2025-10-29T08:11:09.461521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3653 entries, 2012-01-03 to 2025-10-29\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   沥青月差（主力-次主力）             2934 non-null   float64\n",
      " 1   石油沥青：国内企业：库存：中国（周）同差     342 non-null    float64\n",
      " 2   山东汽柴油加权裂解价差              2127 non-null   float64\n",
      " 3   沥青周度产量超季节性/3年            405 non-null    float64\n",
      " 4   WTI连1-连4月差               3481 non-null   float64\n",
      " 5   沥青仓单（仓库+厂库）同差            2674 non-null   float64\n",
      " 6   华东沥青基差                   2932 non-null   float64\n",
      " 7   沥青厂库大样本拼接小样本4周环差         384 non-null    float64\n",
      " 8   BU-SC（期货指数）5年百分位超季节性/5年  891 non-null    float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 285.4 KB\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully as '沥青月差.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "import time\n",
    "import base64\n",
    "from hashlib import sha256\n",
    "from hmac import HMAC\n",
    "\n",
    "import http.client\n",
    "import requests\n",
    "import pandas as pd \n",
    "\n",
    "APPID = \"tubmafwrzhpgfiuf\"\n",
    "SECRET = \"eotpcqbvhycdshwscqnytiwzbgonposs\"\n",
    "\n",
    "\n",
    "def generate_nonce(length=32):\n",
    "    \"\"\"Generate a random nonce.\"\"\"\n",
    "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
    "\n",
    "\n",
    "def get_timestamp():\n",
    "    \"\"\"Get the current timestamp.\"\"\"\n",
    "    return int(time.time())\n",
    "\n",
    "\n",
    "def build_sign_str(appid, nonce, timestamp):\n",
    "    \"\"\"Build the string to be signed.\"\"\"\n",
    "    return f'appid={appid}&nonce={nonce}&timestamp={timestamp}'\n",
    "\n",
    "\n",
    "def calculate_signature(secret, message):\n",
    "    \"\"\"Calculate the HMAC SHA-256 signature.\"\"\"\n",
    "    return base64.urlsafe_b64encode(HMAC(secret.encode('utf-8'), message.encode('utf-8'), sha256).digest()).decode('utf-8')\n",
    "\n",
    "\n",
    "def fetch_indicator_details(indicator_id):\n",
    "    \"\"\"Fetch the details for a specific indicator ID.\"\"\"\n",
    "    nonce = generate_nonce()\n",
    "    timestamp = get_timestamp()\n",
    "    sign_str = build_sign_str(APPID, nonce, timestamp)\n",
    "    signature = calculate_signature(SECRET, sign_str)\n",
    "\n",
    "    headers = {\n",
    "        'nonce': nonce,\n",
    "        'timestamp': str(timestamp),\n",
    "        'appid': APPID,\n",
    "        'signature': signature,\n",
    "        'Accept': \"*/*\",\n",
    "        'Accept-Encoding': \"gzip, deflate, br\",\n",
    "        'User-Agent': \"PostmanRuntime-ApipostRuntime/1.1.0\",\n",
    "        'Connection': \"keep-alive\",\n",
    "    }\n",
    "\n",
    "    url = f\"https://etahub.hzinsights.com/v1/edb/data?EdbCode={indicator_id}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get('Data')\n",
    "    else:\n",
    "        print(\n",
    "            f\"Failed to fetch data for ID {indicator_id}, status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def fetch_indicator_name(indicator_id):\n",
    "    \"\"\"Fetch the name for a specific indicator ID.\"\"\"\n",
    "    nonce = generate_nonce()\n",
    "    timestamp = get_timestamp()\n",
    "    sign_str = build_sign_str(APPID, nonce, timestamp)\n",
    "    signature = calculate_signature(SECRET, sign_str)\n",
    "\n",
    "    headers = {\n",
    "        'nonce': nonce,\n",
    "        'timestamp': str(timestamp),\n",
    "        'appid': APPID,\n",
    "        'signature': signature,\n",
    "        'Accept': \"*/*\",\n",
    "        'Accept-Encoding': \"gzip, deflate, br\",\n",
    "        'User-Agent': \"PostmanRuntime-ApipostRuntime/1.1.0\",\n",
    "        'Connection': \"keep-alive\",\n",
    "    }\n",
    "\n",
    "    url = f\"https://etahub.hzinsights.com/v1/edb/detail?EdbCode={indicator_id}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get('Data').get('EdbName')\n",
    "    else:\n",
    "        print(\n",
    "            f\"Failed to fetch data for ID {indicator_id}, status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # List of indicator IDs you want to fetch\n",
    "    indicator_ids = ['C2307177200','C2505211706219155','C2503171216383686','C2505151727056943',\n",
    "                     'C2108318885','C2505211734547430','C2304191383','C2505220827343696','C2505231722064232']  # Add more IDs as needed\n",
    "\n",
    "    # Dictionary to store DataFrames for each indicator\n",
    "    data_frames = {}\n",
    "\n",
    "    for indicator_id in indicator_ids:\n",
    "        data = fetch_indicator_details(indicator_id)\n",
    "        if data:\n",
    "            # Create a DataFrame with DataTime as index\n",
    "            df = pd.DataFrame(data)\n",
    "            df['DataTime'] = pd.to_datetime(df['DataTime'])\n",
    "            df.set_index('DataTime', inplace=True)\n",
    "            df.sort_index(inplace=True)\n",
    "            # Only keep the 'Value' column and rename it to the indicator ID\n",
    "            df = df[['Value']].rename(columns={'Value': fetch_indicator_name(indicator_id)})\n",
    "            data_frames[indicator_id] = df\n",
    "\n",
    "    # Concatenate all DataFrames along the columns\n",
    "    if data_frames:\n",
    "        result_df = pd.concat(data_frames.values(), axis=1)\n",
    "        print(result_df.info())\n",
    "        result_df.to_excel(\"data_input/沥青月差.xlsx\")\n",
    "        print(\"Data saved successfully as '沥青月差.xlsx'\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
