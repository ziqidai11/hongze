{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T07:43:13.769821Z",
     "iopub.status.busy": "2025-10-29T07:43:13.769254Z",
     "iopub.status.idle": "2025-10-29T07:43:15.474827Z",
     "shell.execute_reply": "2025-10-29T07:43:15.474074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 603 entries, 2018-02-08 to 2025-11-28\n",
      "Data columns (total 6 columns):\n",
      " #   Column                                   Non-Null Count  Dtype  \n",
      "---  ------                                   --------------  -----  \n",
      " 0   纯碱开工率（周度）noseasonal/F 0.1                394 non-null    float64\n",
      " 1   纯碱行业利润/周频                                286 non-null    float64\n",
      " 2   纯碱企业库存8周环差                               400 non-null    float64\n",
      " 3   纯碱开工率（周度）Seasonal/F0.1(预测)               399 non-null    float64\n",
      " 4   纯碱开工率（周度）                                394 non-null    float64\n",
      " 5   纯碱行业利润/周频拟合残差/纯碱开工率（周度）noseasonal/F 0.1  285 non-null    float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 33.0 KB\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully as '纯碱开工率.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "import time\n",
    "import base64\n",
    "from hashlib import sha256\n",
    "from hmac import HMAC\n",
    "\n",
    "import http.client\n",
    "import requests\n",
    "import pandas as pd \n",
    "\n",
    "APPID = \"tubmafwrzhpgfiuf\"\n",
    "SECRET = \"eotpcqbvhycdshwscqnytiwzbgonposs\"\n",
    "\n",
    "\n",
    "def generate_nonce(length=32):\n",
    "    \"\"\"Generate a random nonce.\"\"\"\n",
    "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
    "\n",
    "\n",
    "def get_timestamp():\n",
    "    \"\"\"Get the current timestamp.\"\"\"\n",
    "    return int(time.time())\n",
    "\n",
    "\n",
    "def build_sign_str(appid, nonce, timestamp):\n",
    "    \"\"\"Build the string to be signed.\"\"\"\n",
    "    return f'appid={appid}&nonce={nonce}&timestamp={timestamp}'\n",
    "\n",
    "\n",
    "def calculate_signature(secret, message):\n",
    "    \"\"\"Calculate the HMAC SHA-256 signature.\"\"\"\n",
    "    return base64.urlsafe_b64encode(HMAC(secret.encode('utf-8'), message.encode('utf-8'), sha256).digest()).decode('utf-8')\n",
    "\n",
    "\n",
    "def fetch_indicator_details(indicator_id):\n",
    "    \"\"\"Fetch the details for a specific indicator ID.\"\"\"\n",
    "    nonce = generate_nonce()\n",
    "    timestamp = get_timestamp()\n",
    "    sign_str = build_sign_str(APPID, nonce, timestamp)\n",
    "    signature = calculate_signature(SECRET, sign_str)\n",
    "\n",
    "    headers = {\n",
    "        'nonce': nonce,\n",
    "        'timestamp': str(timestamp),\n",
    "        'appid': APPID,\n",
    "        'signature': signature,\n",
    "        'Accept': \"*/*\",\n",
    "        'Accept-Encoding': \"gzip, deflate, br\",\n",
    "        'User-Agent': \"PostmanRuntime-ApipostRuntime/1.1.0\",\n",
    "        'Connection': \"keep-alive\",\n",
    "    }\n",
    "\n",
    "    url = f\"https://etahub.hzinsights.com/v1/edb/data?EdbCode={indicator_id}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get('Data')\n",
    "    else:\n",
    "        print(\n",
    "            f\"Failed to fetch data for ID {indicator_id}, status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def fetch_indicator_name(indicator_id):\n",
    "    \"\"\"Fetch the name for a specific indicator ID.\"\"\"\n",
    "    nonce = generate_nonce()\n",
    "    timestamp = get_timestamp()\n",
    "    sign_str = build_sign_str(APPID, nonce, timestamp)\n",
    "    signature = calculate_signature(SECRET, sign_str)\n",
    "\n",
    "    headers = {\n",
    "        'nonce': nonce,\n",
    "        'timestamp': str(timestamp),\n",
    "        'appid': APPID,\n",
    "        'signature': signature,\n",
    "        'Accept': \"*/*\",\n",
    "        'Accept-Encoding': \"gzip, deflate, br\",\n",
    "        'User-Agent': \"PostmanRuntime-ApipostRuntime/1.1.0\",\n",
    "        'Connection': \"keep-alive\",\n",
    "    }\n",
    "\n",
    "    url = f\"https://etahub.hzinsights.com/v1/edb/detail?EdbCode={indicator_id}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get('Data').get('EdbName')\n",
    "    else:\n",
    "        print(\n",
    "            f\"Failed to fetch data for ID {indicator_id}, status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # List of indicator IDs you want to fetch\n",
    "    indicator_ids = ['C2504021104597709','C2504021046277214','C2503271229512844',\n",
    "                     'Cstl2504021103421410_250409104447','W006674','C2506061539103819']  # Add more IDs as needed\n",
    "\n",
    "    # Dictionary to store DataFrames for each indicator\n",
    "    data_frames = {}\n",
    "\n",
    "    for indicator_id in indicator_ids:\n",
    "        data = fetch_indicator_details(indicator_id)\n",
    "        if data:\n",
    "            # Create a DataFrame with DataTime as index\n",
    "            df = pd.DataFrame(data)\n",
    "            df['DataTime'] = pd.to_datetime(df['DataTime'])\n",
    "            df.set_index('DataTime', inplace=True)\n",
    "            df.sort_index(inplace=True)\n",
    "            # Only keep the 'Value' column and rename it to the indicator ID\n",
    "            df = df[['Value']].rename(columns={'Value': fetch_indicator_name(indicator_id)})\n",
    "            data_frames[indicator_id] = df\n",
    "\n",
    "    # Concatenate all DataFrames along the columns\n",
    "    if data_frames:\n",
    "        result_df = pd.concat(data_frames.values(), axis=1)\n",
    "        print(result_df.info())\n",
    "        result_df.to_excel(\"data_input/纯碱开工率.xlsx\")\n",
    "        print(\"Data saved successfully as '纯碱开工率.xlsx'\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
